{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bed5aa2-cc60-419e-ae40-2f87055eac4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.avro.functions import from_avro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5927e33b-2f0c-4dde-9222-901f3a21a488",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Parameters are typically passed via Pipeline settings\n",
    "bootstrap = spark.conf.get('pipelines.bootstrap')\n",
    "subscribe = spark.conf.get('pipelines.topic')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "38bd80e4-302f-4f5c-ad07-8717e1777421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1) BRONZE: raw Kafka â†’ Delta (bytes + metadata)\n",
    "\n",
    "@dlt.table(\n",
    "    name = \"bronze\"\n",
    "    comment=\"Raw Kafka records (Bronze)\"\n",
    "    table_properties={\n",
    "        quality=\"bronze\"\n",
    "    }\n",
    "    )\n",
    "\n",
    "\n",
    "def bronze():\n",
    "    df = (spark.readStream\n",
    "           .format('kafka')\n",
    "           .option('kafka.bootstrap.servers', bootstrap)\n",
    "           .option('subscribe', topic)\n",
    "           .option('startingOffsets', 'latest')\n",
    "           .option('failOnDataLoss', 'false')\n",
    "           .load())\n",
    "    return (df.select(\n",
    "        F.col('key').alias('kafka_key'),\n",
    "        F.col('value').alias('value_bytes'),\n",
    "        F.col('timestamp').alias('kafka_ts'),\n",
    "        F.col('topic'), \n",
    "        F.col('partition'), \n",
    "        F.col('offset')\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_bronze_ingest_kafka_DLT",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
